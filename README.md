# PhD-Basic-Knowledge

To enhance my foundational knowledge for research, I plan to study the basics of AI and ML. My research interests include LLM, RL, and ML, so I have chosen some classic textbooks and well-known courses to study.

- [ ]  [PRML](https://github.com/gerdm/prml): I have found a GitHub repository that contains notes and example code for PRML. I plan to use this repository to assist my study of PRML. I plan to complete one or two chapters per week for this book, which has 14 chapters in total, so I will finish it in three months. I will write code and derive the theories myself, documenting my progress in Markdown. I will upload my study progress to my GitHub repository.

    - [√]  Introduction [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/PRML/Chapter%201%20Introduction)
    - [√]  Probability Distributions [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/PRML/Chapter%202%20Probability%20Distributions)
    - [ ]  Linear Models for Regression
    - [ ]  Linear Models for Classification
    - [ ]  Neural Networks
    - [ ]  Kernel Methods
    - [ ]  Sparse Kernel Machines
    - [ ]  Graphical Models
    - [ ]  Mixture Models and EM
    - [ ]  Approximate Inference
    - [ ]  Sampling Methods
    - [ ]  Continuous Latent Variables
    - [ ]  Sequential Data
    - [ ]  Combining Models

- [ ]  [CS224N(For NLP Technique)](https://web.stanford.edu/class/cs224n/index.html#schedule): CS224N-2024 Spring is taught by Stanford. The course covers NLP techniques, including LLM, RLHF, DPO, and more. The problem is that there are no available teaching videos right now; only the 2023 course materials are accessible. Therefore, I will start by learning from the slides. CS224N includes tutorials and assignments. There are four assignments, and I will complete these assignments and take notes. I will complete at least one tutorial per week and upload my progress to my GitHub repository.
    - [√]  Word Vectors [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/CS224N/Chapter%201%20Word%20Vectors)
    - [√]  Word Vectors, Word Senses, and Neural Classifiers [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/CS224N/Chapter%202%20Word%20Vectors%2C%20Word%20Senses%2C%20and%20Neural%20Classifiers) [Assignment1(Done)](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/blob/main/CS224N/Chapter%202%20Word%20Vectors%2C%20Word%20Senses%2C%20and%20Neural%20Classifiers/Assignment1/student/exploring_word_vectors.ipynb)
    - [√]  Backpropagation and Neural Network Basics [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/CS224N/Chapter%203%20BP%20and%20Neural%20Network) 
    - [√]  Dependency Parsing [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/CS224N/Chapter%204%20Dependency%20Parsing) [Assignment2_Written(Done)](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/blob/main/CS224N/Chapter%203%20BP%20and%20Neural%20Network/Assgnment%202/CS224N_Assignment2_Written.pdf) [Assignment2_Coding(Done)](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/CS224N/Chapter%203%20BP%20and%20Neural%20Network/Assgnment%202/student)
    - [ ]  Recurrent Neural Networks
    - [ ]  Sequence to Sequence Models and Machine Translation
    - [ ]  LLM intro
    - [ ]  Transformers
    - [ ]  Pretraining
    - [ ]  Post-training (RLHF, SFT, DPO)
    - [ ]  Benchmarking and Evaluation
    - [ ]  Efficient Neural Network Training
    - [ ]  Speech Brain-Computer Interface
    - [ ]  Reasoning and Agents
    - [ ]  Life after DPO
    - [ ]  ConvNets, Tree Recursive Neural Networks and Constituency Parsing
    - [ ]  An Introduction to Responsible NLP

- [ ]  [EasyRL](https://datawhalechina.github.io/easy-rl/): Easy RL is a tutorial about Reinforcement Learning recommended by Prof. Yaodong Yang. This book includes 13 chapters. Unlike PRML and CS224N, Easy RL has fewer coding tasks but more theory. Therefore, I will focus on the theoretical proof of each algorithm. I will also complete at least one chapter per week.
    - [√]  Foundamental of Reinforcement [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/EasyRL/Chapter%201%20Foundamental%20of%20Reinforcement%20Learning)
    - [√]  MDP [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/EasyRL/Chapter%202%20MDP)
    - [√]  Tabular Methods [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/EasyRL/Chapter%203%20Tabular%20Methods)
    - [√]  Policy Gradient [Note](https://github.com/mingxuZhang2/PhD-Basic-Knowledge/tree/main/EasyRL/Chapter%204%20Policy%20Gradient)
    - [ ]  PPO
    - [ ]  DQN Basic
    - [ ]  DQN Tricks
    - [ ]  DQN for Continue Actions Space
    - [ ]  AC Algorithm
    - [ ]  Sparse Reward
    - [ ]  Imitation Learning
    - [ ]  DDPG
    - [ ]  Introduction to AlphaStar
    
- [ ]  Research: I will spend half of my time enhancing my basic knowledge and the other half on research. I will conduct the following research projects.
    - [ ]  Weak-to-Strong Generalization.
    - [ ]  SafeRL.

- [ ]  Paper Reading: Meanwhile, I think I need to read some classic papers, but I am not sure which ones to read yet. So this section remains to be discussed. I will read some LLM papers on weak-to-strong generalization and scalable oversight, which are related to my research. I will read at least three papers per week.
    - [ ]  [Weak-to-Strong Extrapolation Expedites Alignment](https://arxiv.org/abs/2404.16792)
    - [ ]  [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781)
    - [ ] [GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162.pdf)
    - [ ] [Improving Word Representations Via Global Context And Multiple Word Prototypes](https://aclanthology.org/P12-1092.pdf)
    - [ ] [A Survey of the State of Explainable AI for Natural Language Processing](https://arxiv.org/pdf/2010.00711)
    - [ ] [Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI](https://arxiv.org/pdf/1910.10045)