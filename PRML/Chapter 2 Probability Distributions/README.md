# PRML Chapter 2: Probability Distributions


Likelihood and probability: The probability of the data is when we know the parameters of the model, which means in the case of parameters $\theta$, the events $A$ occur which can denoted as $P(A|\theta)$. The likelihood of the parameters is the probability of the parameters when we know the data, which means in the case of data $D$, the parameters $\theta$ occur which can denoted as $P(\theta|D)$. The likelihood function is given by $P(D|\theta)$. We need to do MLE because MLE can find the parameters that maximize the likelihood function, which means the probability of the events $A$ occur is maximized.

## 2.1 Binary Variables

Consider a binary variable $x \in \{0,1\}$ which $x=1$ respresents the head of a coin and $x=0$ represents the tail of a coin. The probability of the head of a coin is given by $P(x=1) = \mu$ and the probability of the tail of a coin is given by $P(x=0) = 1-\mu$. The probability of the binary variable $x$ can be written as:

$$
P(x|\mu) = \mu^x(1-\mu)^{1-x}
$$

where $\mu \in [0,1]$ is the parameter of the distribution. This distribution is called the Bernoulli distribution. When $x=1$, the probability of the head of a coin is given by $\mu$ and when $x=0$, the probability of the tail of a coin is given by $1-\mu$. The expected value of the Bernoulli distribution is given by:

$$
E[x] = \sum_{x=0}^{1} xP(x) = 0 \times (1-\mu) + 1 \times \mu = \mu
$$

The variance of the Bernoulli distribution is given by:

$$
Var[x] = E[x^2] - E[x]^2 = \mu - \mu^2 = \mu(1-\mu)
$$

And suppose we have a data set $\mathcal{D} = \{x_1,x_2,\ldots,x_N\}$ where $x_i \in \{0,1\}$ and the data set is generated by a coin with probability $\mu$. The likelihood function of the data set $\mathcal{D}$ is given by:

$$
P(\mathcal{D}|\mu) = \prod_{n=1}^{N} P(x_n|\mu) = \prod_{n=1}^{N} \mu^{x_n}(1-\mu)^{1-x_n}
$$

The likelihood function means that the probability of the data set $\forall x \in \mathcal{D}$, the events $x$ all occur. And the log likelihood function is given by:

$$
\ln P(\mathcal{D}|\mu) = \sum_{n=1}^{N} \ln P(x_n|\mu) = \sum_{n=1}^{N} \{x_n \ln \mu + (1-x_n) \ln (1-\mu)\}
$$

Due to the $\mu$ can be seen as a constant, so the log likelihood function is only depends on the sum of the observed data points $x_n$. We want to maximize the likelihood function, so we can take derivative of the log likelihood function with respect to $\mu$ and set it to zero:

$$
\frac{d}{d\mu} \ln P(\mathcal{D}|\mu) = \sum_{n=1}^{N} \left( \frac{x_n}{\mu} - \frac{1-x_n}{1-\mu} \right) = 0
$$

And we can solve the above equation to get the maximum likelihood estimator of $\mu$:

$$
\mu_{ML} = \frac{1}{N} \sum_{n=1}^{N} x_n
$$

Which means if we want to estimate the probability of the head of a coin, we can just calculate the proportion of the head of a coin in the data set. Using the statistical average of the dataset to apporximate the probability of the head of a coin is a reasonable method. It can maximize the likelihood function of the data set. And then, have the minimized error of the estimation.

For $x$ is a binary value, if we count the number of the head of a coin in the dataset is $m$ and the length of dataset is $N$, the probability of the head of a coin is given by:

$$
\mu_{ML} = \frac{m}{N}
$$

If we observe 3 data points and the data set is $\mathcal{D} = \{1,1,1\}$, the probability of the head of a coin is given by:

$$
\mu_{ML} = \frac{3}{3} = 1
$$

$\mu_{ML}$ is used to do decision-making when we meet new data. So it is obviously impossible in real world that the coin is always the head. The phenomenon is called overfitting as we only want to maximize the likelihood function.

If we have $m$ numbers that $x=1$ occurs and the total number of the data set is $N$, since each event is independent, the probability of this is called the binomial distribution:

$$
P(m|N,\mu) = \binom{N}{m} \mu^m(1-\mu)^{N-m}
$$

where $\binom{N}{m}$ is the binomial coefficient. This is says that we will choose $m$ events that happen in total $N$ events and another $N-m$ events that do not happen. So there will be a binomial coefficient $\binom{N}{m}$ ways to choose $m$ events from $N$ events. The expected value of the binomial distribution is given by:

$$
E[m] = \sum_{m=0}^{N} mP(m) = N\mu
$$

The variance of the binomial distribution is given by:

$$
Var[m] = E[m^2] - E[m]^2 = N\mu(1-\mu)
$$

### 2.1.1 The Beta Distribution

We have discussed above that if we only maximize the likelihood function, we may meet over-fitting problem. And the key to Bayesian theory is using prior probility to estimate the posterior probability. Previously, we only consider $\mu$ is a constant, we can regard $\mu$ as a random variable and use the prior probability $p(\mu)$ to estimate the posterior probability.

Conjudacy prior distribution: If the prior distribution $p(\mu)$ has the same distribution form(e.g. both Gauss Distribution) as the posterior distribution $p(\mu|\mathcal{D})$, the prior distribution is called the conjudacy prior distribution of the likelihood function.

Due to the prior distribution is random, we can choose any form of the prior distribution. We need to choose one that is easy to calculate for the posterior distribution. So we can choose the Beta distribution as the prior distribution of the Bernoulli distribution. The Beta distribution is given by:

$$
Beta(\mu|a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}
$$

where $a$ and $b$ are the parameters of the Beta distribution, $\Gamma(x)$ is the gamma function which is given by:

$$
\Gamma(x) = \int_{0}^{\infty} u^{x-1}e^{-u}du
$$

The expected value of the Beta distribution is given by:

$$
E[\mu] = \frac{a}{a+b}
$$

The variance of the Beta distribution is given by:

$$
Var[\mu] = \frac{ab}{(a+b)^2(a+b+1)}
$$

In beta distrbution, the $\gamma$ function is used to normalized the distribution, ensuring the integral of the distribution is 1. For any $a$ and $b$, the integral of the Beta distribution is 1, so that:

$$
\int_{0}^{1} Beta(\mu|a,b)d\mu = 1
$$

![beta distribution](/PRML/Chapter%202%20Probability%20Distributions/fig/image1.png)


The image above shows the curve in different hyperparameters. Let's back to the question. We need to choose the conjugate prior distribution of the Bernoulli distribution and we have already chosen the beta distribution. Consider how to calculate the posterior distribution of the Bernoulli distribution. The posterior distribution is given by:

$$
P(\mu|\mathcal{D}) = \frac{P(\mathcal{D}|\mu)P(\mu)}{P(\mathcal{D})}
$$

where $P(\mathcal{D})$ is the normalization factor. The posterior distribution is proportional to the product of the likelihood function and the prior distribution. And we know that $P(D)$ is a constant, so $P(\mu|\mathcal{D}) \propto P(\mathcal{D}|\mu)P(\mu)$. The likelihood function in Bernoulli distribution is given by:

$$
P(\mathcal{D}|\mu) = \prod_{n=1}^{N} \mu^{x_n}(1-\mu)^{1-x_n}
$$

Combine the likelihood function and the prior distribution, we can get the posterior distribution of the Bernoulli distribution:

$$
P(\mu|\mathcal{D}) \propto \mu^{\sum_{n=1}^{N} x_n + a - 1}(1-\mu)^{N - \sum_{n=1}^{N} x_n + b - 1}
$$

It is still a Beta distribution and only the parameters are changed. The posterior distribution is given by:

$$
P(\mu|\mathcal{D}) = Beta(\mu|\sum_{n=1}^{N} x_n + a, N - \sum_{n=1}^{N} x_n + b)
$$

The prior distribution is given by $Beta(\mu|a,b)$. As we can see that, after observing the data set, the parameters of the prior distribution are changed. The benefit of using the beta distribution is the prior distribution and posterior distribution remain the same form. And when we calculate the expectation and variance of the posterior distribution, we can avoid the complex integral calculation and use the formula of the expectation and variance of the beta distribution.

![difference before and after ovserving](/PRML/Chapter%202%20Probability%20Distributions/fig/image2.png)

The image above shows the difference before and after observing the dataset. We have a prior distritbution and after we observe the dataset(likelihood function), the posterior distritbution changed. In the figure, we can see that the likelihood function is increased as $\mu$ increases. As the result, the posterior distribution is also increased compared with prior distribution along with the same value of $\mu$. At the same time, the over-fitting problem is also avoid in some degree, the posterior distribution is moew smooth than the likelihood function.

Let's have a more general discussion. The Machine Learning is aimed to update the parameter $\theta$ when observing the dataset $\mathcal{D}$ in different batches which can be formulated as a joint distribution $p(\theta,\mathcal{D})$. We have:

$$\mathbb{E}_\theta[\theta] = \mathbb{E}_\mathcal{D}[\mathbb{E}[\theta|\mathcal{D}]]$$

Because:


$$
\mathbb{E}_\theta[\theta] = \int \theta p(\theta)d\theta
$$

$$ 
\mathbb{E}_\mathcal{D}[\mathbb{E}[\theta|\mathcal{D}]] = \int \left \{ \int \theta p(\theta|\mathcal{D})d\theta\right \} p(\mathcal{D}) d\mathcal{D}
$$

$$
= \int \theta \left \{ \int  p(\theta,\mathcal{D}) d\mathcal{D}\right \} d\theta
$$

$$
= \int \theta p(\theta)d\theta
$$

$$
= \mathbb{E}_\theta[\theta]
$$

So it means the posterior mean of $\theta$ is equal to the prior mean of $\theta$. So if we use MLE to estimate the parameter $\theta$, it is unbiased estimation.

## 2.2 Multinomial Variables
